{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Installation and Imports ---\n",
    "!pip install -q sentence-transformers chromadb torch\n",
    "\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import os # Included for cleanliness, though not strictly needed here\n",
    "\n",
    "# --- Configuration ---\n",
    "HF_REPO_ID = \"zacCMU/miniLM2-ENG3\"\n",
    "\n",
    "\n",
    "\n",
    "# --- 3. Model Download and Load ---\n",
    "# SentenceTransformer handles downloading the model from the Hub\n",
    "print(f\"Downloading and loading model: {HF_REPO_ID}\")\n",
    "embedder = SentenceTransformer(HF_REPO_ID)\n",
    "\n",
    "\n",
    "# --- 4. ChromaDB Embedding Function (Custom Wrapper) ---\n",
    "# This wrapper correctly implements the ChromaDB EmbeddingFunction interface.\n",
    "class CustomSBERTEmbeddingFunction(chromadb.EmbeddingFunction):\n",
    "    def __init__(self, model):\n",
    "        # We store the loaded SentenceTransformer model instance\n",
    "        self._model = model\n",
    "    def __call__(self, texts):\n",
    "        # Outputs a list of lists of floats as ChromaDB expects\n",
    "        embeddings = self._model.encode(texts, convert_to_tensor=False).tolist()\n",
    "        return embeddings\n",
    "    # Mandatory name method for ChromaDB's validation logic\n",
    "    def name(self):\n",
    "        return \"custom_sbert_wrapper\"\n",
    "\n",
    "# Instantiate the wrapper with the downloaded model\n",
    "custom_ef = CustomSBERTEmbeddingFunction(embedder)\n",
    "\n",
    "# --- 5. Data Preparation and Vector Store Building ---\n",
    "documents = [\n",
    "    \"A **PID controller** (Proportional-Integral-Derivative controller) is a control loop mechanism that continuously calculates an error value as the difference between a desired setpoint and a measured process variable.\",\n",
    "    \"The **Von Neumann architecture** separates memory and I/O into two distinct buses, unlike the Harvard architecture which uses shared buses.\",\n",
    "    \"**Finite Element Analysis (FEA)** is a computational method for predicting how a product reacts to real-world forces, heat, vibration, and fluid flow. It uses a mesh to discretize complex geometries.\",\n",
    "    \"**Thermodynamics' Second Law** states that the total entropy of an isolated system can only increase over time. It can never decrease.\",\n",
    "    \"The **Shannon-Weaver model** of communication consists of six elements: Sender, Encoder, Channel, Noise, Decoder, and Receiver.\",\n",
    "    \"In software engineering, **Agile methodologies** focus on iterative development, delivering working software frequently, and adapting to change.\",\n",
    "]\n",
    "\n",
    "# Build the Vector Store (in-memory)\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"engineering_corpus\",\n",
    "    embedding_function=custom_ef\n",
    ")\n",
    "\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    ids=[f\"doc_{i}\" for i in range(len(documents))]\n",
    ")\n",
    "print(f\"âœ… Indexed {len(documents)} documents into ChromaDB.\")\n",
    "\n",
    "# --- 6. Retrieval Test ---\n",
    "query = \"In computer systems, how is memory accessed differently from input/output components?\"\n",
    "\n",
    "print(f\"\\n--- Testing Retrieval for Query: '{query}' ---\")\n",
    "\n",
    "# Use the custom model via the collection to find the most relevant context\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=2,  # Retrieve the top 2 results\n",
    "    include=['documents', 'distances']\n",
    ")\n",
    "\n",
    "# --- 7. Final Retrieval Output ---\n",
    "print(\"\\n--- Top Retrieved Contexts ---\")\n",
    "\n",
    "for i, (doc, dist) in enumerate(zip(results['documents'][0], results['distances'][0])):\n",
    "    print(f\"{i+1}. Distance: {dist:.4f}\")\n",
    "    print(f\"   Document: {doc}\")\n",
    "\n",
    "# --- Optional: Basic Semantic Test (using model directly) ---\n",
    "# NOTE: This part was kept separate from the main RAG logic for clarity,\n",
    "# but it verifies the model's ability to calculate similarity.\n",
    "sentences_to_test = [\n",
    "    \"The Von Neumann architecture uses shared buses.\",\n",
    "    \"The Von Neumann architecture separates memory and I/O.\",\n",
    "    \"This has nothing to do with physics or communication theory.\"\n",
    "]\n",
    "\n",
    "embeddings = embedder.encode(sentences_to_test, convert_to_tensor=True)\n",
    "similarity = util.cos_sim(embeddings[0], embeddings[1])\n",
    "dissimilarity = util.cos_sim(embeddings[0], embeddings[2])\n",
    "\n",
    "print(\"\\n--- Model Direct Similarity Test ---\")\n",
    "print(f\"Related Similarity: {similarity.item():.4f}\")\n",
    "print(f\"Unrelated Similarity: {dissimilarity.item():.4f}\")\n",
    "\n",
    "\n",
    "def add_documents_to_collection(collection: chromadb.api.models.Collection, docs: list[str]):\n",
    "    \"\"\"\n",
    "    Adds a list of text documents to a given ChromaDB collection.\n",
    "\n",
    "    Args:\n",
    "        collection: The ChromaDB Collection object.\n",
    "        docs: A list of string documents to be indexed.\n",
    "    \"\"\"\n",
    "    ids = [f\"doc_{i}\" for i in range(len(docs))]\n",
    "    collection.add(\n",
    "        documents=docs,\n",
    "        ids=ids\n",
    "    )\n",
    "\n",
    "def retrieve_documents(collection: chromadb.api.models.Collection, query: str, n_results: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves the top N relevant documents from the ChromaDB collection based on a query.\n",
    "\n",
    "    Args:\n",
    "        collection: The ChromaDB Collection object.\n",
    "        query: The search query string.\n",
    "        n_results: The number of documents to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the retrieval results (documents and distances).\n",
    "    \"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results,\n",
    "        include=['documents', 'distances']\n",
    "    )\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
